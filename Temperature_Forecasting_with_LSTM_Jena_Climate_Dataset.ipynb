{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5Y/WnWSajoapnUC4uOsee",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rizalpernata1/Temperature_Forecasting_with_LSTM/blob/main/Temperature_Forecasting_with_LSTM_Jena_Climate_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "YNRf7Kr3J3k1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZSkyt2gShLns"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "3aNKoSzaJ_HG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/jena_climate_2009_2016.csv')"
      ],
      "metadata": {
        "id": "hOZuHgWTlMmy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing the data\n",
        "\n",
        "Performing data preprocessing steps, such as converting the date format, setting the index, and filling missing values."
      ],
      "metadata": {
        "id": "0F25fEJnKMG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date Time'] = pd.to_datetime(df['Date Time'], format='%d.%m.%Y %H:%M:%S')\n",
        "df = df.set_index('Date Time')\n",
        "df = df.resample('H').mean().fillna(method='ffill')  # Resample to hourly data and forward fill missing values"
      ],
      "metadata": {
        "id": "cLeq9Z9ZlU9m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecting the variable and scaling the data:\n",
        "\n",
        "Selecting the variable of interest (e.g., temperature) and scaling the data using the MinMaxScaler to normalize it."
      ],
      "metadata": {
        "id": "c3SZkNPrKbSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df['T (degC)'].values.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "lkqbaj8alX8s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)"
      ],
      "metadata": {
        "id": "mppep9V1gqP2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the data\n",
        "\n",
        "Splitting the dataset into training and testing data."
      ],
      "metadata": {
        "id": "-ODbEpXRKo6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(data_scaled) * 0.8)\n",
        "train_data = data_scaled[:train_size]\n",
        "test_data = data_scaled[train_size:]"
      ],
      "metadata": {
        "id": "3v-3GJs_VNfQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation\n",
        "\n",
        "Defining a function to prepare the data in the form of sequences with the given time steps."
      ],
      "metadata": {
        "id": "Ag32PcyxK5cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data, n_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data)-n_steps-1):\n",
        "        X.append(data[i:(i+n_steps), 0])\n",
        "        y.append(data[i+n_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "n_steps = 24  # Number of time steps to consider\n",
        "X_train, y_train = prepare_data(train_data, n_steps)\n",
        "X_test, y_test = prepare_data(test_data, n_steps)"
      ],
      "metadata": {
        "id": "SsHw8N8VVR3o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reshape input data to be 3-dimensional in the form [samples, time steps, features]"
      ],
      "metadata": {
        "id": "R6pSCnEqLgiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
      ],
      "metadata": {
        "id": "BGpWgOftVV0x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the LSTM model\n",
        "\n",
        "Building the LSTM model using the Sequential API from Keras, adding LSTM and Dense layers."
      ],
      "metadata": {
        "id": "SM-R8Uz7LvWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(n_steps, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "GjJBsUjXVgOJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluate the model\n",
        "\n",
        "Training the model using the training data.\n",
        "\n",
        "Evaluating the performance of the model using both the training and testing data."
      ],
      "metadata": {
        "id": "f-qrvYoKL8pA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)"
      ],
      "metadata": {
        "id": "jl8eNaBGVgyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98223a7d-7e90-488f-86e5-4cb31d2e89d5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3505/3505 [==============================] - 51s 14ms/step - loss: 0.0025\n",
            "Epoch 2/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.8893e-04\n",
            "Epoch 3/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.3538e-04\n",
            "Epoch 4/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.2700e-04\n",
            "Epoch 5/50\n",
            "3505/3505 [==============================] - 43s 12ms/step - loss: 1.2445e-04\n",
            "Epoch 6/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.2023e-04\n",
            "Epoch 7/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.1946e-04\n",
            "Epoch 8/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.1633e-04\n",
            "Epoch 9/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.1474e-04\n",
            "Epoch 10/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.1557e-04\n",
            "Epoch 11/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.1298e-04\n",
            "Epoch 12/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.1286e-04\n",
            "Epoch 13/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.1296e-04\n",
            "Epoch 14/50\n",
            "3505/3505 [==============================] - 44s 13ms/step - loss: 1.1123e-04\n",
            "Epoch 15/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.1121e-04\n",
            "Epoch 16/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.0869e-04\n",
            "Epoch 17/50\n",
            "3505/3505 [==============================] - 44s 13ms/step - loss: 1.1071e-04\n",
            "Epoch 18/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.1022e-04\n",
            "Epoch 19/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0866e-04\n",
            "Epoch 20/50\n",
            "3505/3505 [==============================] - 43s 12ms/step - loss: 1.0768e-04\n",
            "Epoch 21/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0853e-04\n",
            "Epoch 22/50\n",
            "3505/3505 [==============================] - 43s 12ms/step - loss: 1.0645e-04\n",
            "Epoch 23/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0656e-04\n",
            "Epoch 24/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0625e-04\n",
            "Epoch 25/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.0593e-04\n",
            "Epoch 26/50\n",
            "3505/3505 [==============================] - 43s 12ms/step - loss: 1.0471e-04\n",
            "Epoch 27/50\n",
            "3505/3505 [==============================] - 43s 12ms/step - loss: 1.0524e-04\n",
            "Epoch 28/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0380e-04\n",
            "Epoch 29/50\n",
            "3505/3505 [==============================] - 39s 11ms/step - loss: 1.0407e-04\n",
            "Epoch 30/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0332e-04\n",
            "Epoch 31/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0282e-04\n",
            "Epoch 32/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.0336e-04\n",
            "Epoch 33/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.0314e-04\n",
            "Epoch 34/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.0270e-04\n",
            "Epoch 35/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0290e-04\n",
            "Epoch 36/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.0255e-04\n",
            "Epoch 37/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0224e-04\n",
            "Epoch 38/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0201e-04\n",
            "Epoch 39/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.0189e-04\n",
            "Epoch 40/50\n",
            "3505/3505 [==============================] - 42s 12ms/step - loss: 1.0212e-04\n",
            "Epoch 41/50\n",
            "3505/3505 [==============================] - 43s 12ms/step - loss: 1.0105e-04\n",
            "Epoch 42/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0031e-04\n",
            "Epoch 43/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0087e-04\n",
            "Epoch 44/50\n",
            "3505/3505 [==============================] - 40s 11ms/step - loss: 1.0086e-04\n",
            "Epoch 45/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0062e-04\n",
            "Epoch 46/50\n",
            "3505/3505 [==============================] - 40s 11ms/step - loss: 1.0037e-04\n",
            "Epoch 47/50\n",
            "3505/3505 [==============================] - 41s 12ms/step - loss: 1.0040e-04\n",
            "Epoch 48/50\n",
            "3505/3505 [==============================] - 40s 12ms/step - loss: 1.0043e-04\n",
            "Epoch 49/50\n",
            "3505/3505 [==============================] - 40s 11ms/step - loss: 1.0024e-04\n",
            "Epoch 50/50\n",
            "3505/3505 [==============================] - 40s 11ms/step - loss: 1.0014e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f210d1c2230>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
        "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Training loss: {train_loss:.4f}')\n",
        "print(f'Testing loss: {test_loss:.4f}')"
      ],
      "metadata": {
        "id": "8uoFi_IZVqVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd37016-77aa-4446-d9da-c1d3a8fbfb94"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.0001\n",
            "Testing loss: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions\n",
        "\n",
        "Making predictions on the testing data using the trained model."
      ],
      "metadata": {
        "id": "0oyh_3GxMKis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXsV_mGRJINK",
        "outputId": "54e9ebed-734b-470a-fcc6-f37ba42b7e7b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438/438 [==============================] - 2s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling back and Evaluating the performance\n",
        "\n",
        "Reverting the scaled predictions back to the original scale using inverse transformation.\n",
        "\n",
        "Calculating the Root Mean Squared Error (RMSE) to measure the prediction error of the model."
      ],
      "metadata": {
        "id": "Rsw7J8lAMWZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = scaler.inverse_transform(predictions)\n",
        "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "y1bI8qtgJMyP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = np.sqrt(np.mean((predictions - y_test) ** 2))\n",
        "print(f'Root Mean Squared Error: {rmse:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RlVcC--JRZ7",
        "outputId": "4486cdc5-b7bc-414c-d139-1a343d6b0e77"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error: 0.5741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0V9IZ_qoJTY6"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}